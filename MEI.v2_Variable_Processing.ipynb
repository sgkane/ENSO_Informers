{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92bacfa6",
   "metadata": {},
   "source": [
    "This notebook is designed to prepare the data from the MEI.v2 folder (surface temperature, pressure, u and v wind components, and outgoing longwave radiation (OLR)) in a format that can be readily input into the multidimentsional positional encoding + informer for use.\n",
    "\n",
    "In particular, the data are all put on a uniform 4 degree by 4 degree grid and are reported monthly starting January 1979 and ending December 2022. (Note: this requires taking the average of the OLR data, which is recorded daily in the MEI.v2 folder, for consistency with the other variables, which are recorded monthly.)\n",
    "\n",
    "Variables are reported as 5 Numpy arrays (one for each variable) with shape latitude x longitude x time (months since January 1979). Only variables in the ENSO region of the Pacific (30°S–30°N and 100°E–70°W, the region used to calculate the MEI) are returned (ex. the Numpy arrays do not include the variables for the full globe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "817f13ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "import netCDF4 as nc\n",
    "import pygrib\n",
    "from scipy.interpolate import RegularGridInterpolator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8077b946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ IN THE DATA\n",
    "# uses data in the MEI.v2 folder\n",
    "\n",
    "years = np.arange(1979,2022,1,dtype=int)\n",
    "years_str = years.astype(str)\n",
    "\n",
    "num_yrs = len(years)\n",
    "\n",
    "def open_anl_surf(variable, yrs):\n",
    "    '''\n",
    "    Opens the desired data (SST, 2 wind components, pressure) from the anl_surf folder for the desired years\n",
    "    \n",
    "    possible inputs for data (input as strings):\n",
    "    - \"pres\": pressure\n",
    "    - \"ugrd\": u component of wind\n",
    "    - \"vgrd\": v component of wind\n",
    "    - \"tmp\": surface temperature (assumed here to be SST)\n",
    "    yrs is a list of strings denoting the desired years of data\n",
    "    \n",
    "    outputs data for that variable as an array of gribs\n",
    "    '''\n",
    "    num_yrs = len(years)\n",
    "    \n",
    "    path_pt1 = 'MEI.v2/ds628.1/anl_surf/'\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for year in yrs:\n",
    "        folder = path_pt1 + year + '/'\n",
    "        search_for = \"*\" + variable + '*'\n",
    "        file = glob(folder + search_for)[0]\n",
    "        \n",
    "        grbs = pygrib.open(file)\n",
    "        \n",
    "        data.append(grbs)\n",
    "    \n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "def open_olr(yrs):\n",
    "    '''\n",
    "    opens + saves outgoing longwave radiation data from the olr folder\n",
    "    \n",
    "    yrs is a list of strings denoting the desired years of data\n",
    "    \n",
    "    outputs outgoing longwave radiation data as an array of NetCDF datasets\n",
    "    '''\n",
    "    file = 'MEI.v2/OLR_daily/olr-daily_v01r02_19790101_19791231.nc'\n",
    "    \n",
    "    num_yrs = len(years)\n",
    "    \n",
    "    path_pt1 = 'MEI.v2/OLR_daily/'\n",
    "    \n",
    "    data = []\n",
    "    \n",
    "    for year in yrs:\n",
    "        folder = path_pt1 + year + '/'\n",
    "        file = path_pt1 + 'olr-daily_v01r02_' +year+ '0101_' +year+ '1231.nc'\n",
    "        \n",
    "        ds = nc.Dataset(file)\n",
    "        \n",
    "        data.append(ds)\n",
    "    \n",
    "    return np.array(data)\n",
    "\n",
    "\n",
    "# read in data here, save data as arrays of grbs or NetCDF DataSets\n",
    "pres_data = open_anl_surf('pres', years_str)\n",
    "ugrd_data = open_anl_surf('ugrd', years_str)\n",
    "vgrd_data = open_anl_surf('vgrd', years_str)\n",
    "tmp_data = open_anl_surf('tmp', years_str) # only NetCDF array\n",
    "\n",
    "olr_data = open_olr(years_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "862675b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_nans(data):\n",
    "    '''\n",
    "    Replaces outliers (value 4.5 sigma above or below mean from whole period) values with 2D inerpolated values\n",
    "    \n",
    "    follows from Wolter and Timlin (1993)\n",
    "    \n",
    "    returns cleaned data\n",
    "    '''\n",
    "    # WAS NOT NEEDED--no NaN values found in MEI.v2 data!!\n",
    "    \n",
    "    return cleaned_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "40d8a0e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make uniform grid data from the grib files, save as a single array\n",
    "\n",
    "def make4x4_grid_grib(grb):\n",
    "    '''\n",
    "    Puts data from a given grib object on a uniform 4 degree by 4 degree grid\n",
    "    Follows from Wolter and Timlin (1993) and Wolter and Timlin (2011)\n",
    "    \n",
    "    returns 4x4 latitudes, longitudes, data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # get latitude and longitude values\n",
    "    data = grb.values\n",
    "    lat = grb.latlons()[0][:,0]\n",
    "    lon = grb.latlons()[1][0,:]\n",
    "    \n",
    "    # make an interpolating function for the original data\n",
    "    interp = RegularGridInterpolator((lat, lon), data)\n",
    "    \n",
    "    # then data are interpolated on a 4 degree grid using the median values of the 2 degree grids\n",
    "    latitude4 = np.flip(np.arange(-88.0, 90.0, 4.0)) # goes from 88 to -88\n",
    "    longitude4 = np.arange(2.0, 360.0, 4.0) # only goes up to 358\n",
    "    \n",
    "    # longitude is like x coordinate, latitude is like y coordinate\n",
    "    Lon4, Lat4 = np.meshgrid(longitude4, latitude4)\n",
    "    \n",
    "    data4 = interp((Lat4, Lon4))\n",
    "    \n",
    "    return Lat4, Lon4, data4\n",
    "\n",
    "def construct_data_array_fromgrib(grbs_array):\n",
    "    '''\n",
    "    Constructs an array of data with each index alonh axis=2 corresponding to a month of data\n",
    "    \n",
    "    input grbs_array is the output from open_anl_surf for a given variable\n",
    "    \n",
    "    '''\n",
    "    latitude4 = np.flip(np.arange(-88.0, 90.0, 4.0)) # goes from 88 to -88\n",
    "    longitude4 = np.arange(2.0, 360.0, 4.0) # only goes up to 358.0\n",
    "    lat_mask = (-30 <= latitude4) & (30 >= latitude4)\n",
    "    lon_mask = (100 <= longitude4) & (290 >= longitude4)\n",
    "    \n",
    "    Lon4, Lat4 = np.meshgrid(longitude4, latitude4)\n",
    "    \n",
    "    # select ENSO region\n",
    "    lat4_mask = (-30 <= Lat4) & (30 >= Lat4)\n",
    "    lon4_mask = (100 <= Lon4) & (290 >= Lon4)\n",
    "    ENSO_area_mask = lat4_mask & lon4_mask\n",
    "    ENSO_3D_mask = np.repeat(ENSO_area_mask[:, :, np.newaxis], (num_yrs*12), axis=2)\n",
    "    \n",
    "    full_data_array = np.zeros((len(latitude4), len(longitude4), num_yrs*12))\n",
    "    \n",
    "    for i,grbs in enumerate(grbs_array):\n",
    "        \n",
    "        for j,grb in enumerate(grbs.select()):\n",
    "            \n",
    "            Lat, Lon, data = make4x4_grid_grib(grb)\n",
    "            full_data_array[:,:,(12*i)+j] = data\n",
    "    \n",
    "    return np.reshape(full_data_array[ENSO_3D_mask], (len(latitude4[lat_mask]), len(longitude4[lon_mask]), (num_yrs*12)))\n",
    "\n",
    "pressure = construct_data_array_fromgrib(pres_data)\n",
    "temperature = construct_data_array_fromgrib(tmp_data)\n",
    "uwind = construct_data_array_fromgrib(ugrd_data)\n",
    "vwind = construct_data_array_fromgrib(vgrd_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3dabd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_seasons_from_days(data):\n",
    "    '''\n",
    "    Takes data in daily values NetCDF format, constructs it into sliding seasonal bins of data\n",
    "    returns lat, lon, array of seasonal olr\n",
    "    \n",
    "    (seasons referring to the overlapping bimonthly seasons)\n",
    "    '''\n",
    "    # first just grab the lat and lon coordinates from the first NetCDF\n",
    "    first_ds = data[0]\n",
    "    lat = first_ds['lat'][:]\n",
    "    lon = first_ds['lon'][:]\n",
    "    \n",
    "    # save all of the daily olr measurements to one big array!\n",
    "    daily_data = np.zeros((len(lat), len(lon), 0))\n",
    "    \n",
    "    for ds in data:\n",
    "        # get the data in the correct shape (lat, lon, day)\n",
    "        olr = ds['olr'][:]\n",
    "        olr1 = np.swapaxes(olr,0,1)\n",
    "        olr2 = np.swapaxes(olr1,1,2)\n",
    "        \n",
    "        daily_data = np.concatenate((daily_data, olr2), axis=2)\n",
    "    \n",
    "    # add some extra zeros on the end as a buffer\n",
    "    daily_data = np.concatenate((daily_data, np.zeros((len(lat), len(lon), 31))), axis=2)\n",
    "    daily_data = daily_data[:,:,1:]\n",
    "    \n",
    "    # length of a month\n",
    "    month_lens = np.array([31,28,31,30,31,30,31,31,30,31,30,31])\n",
    "    month_lens_lpyr = np.array([31,29,31,30,31,30,31,31,30,31,30,31])\n",
    "    \n",
    "    monthly_data = np.zeros((len(lat), len(lon), (num_yrs*12)))\n",
    "    \n",
    "    # track number of days past, starting at 31 because of the 0 padding\n",
    "    day_tracker = 0\n",
    "    \n",
    "    # now we need to average the daily data into the months\n",
    "    for i, year in enumerate(years):\n",
    "        if year%4 == 0:\n",
    "            months = month_lens_lpyr\n",
    "        else:\n",
    "            months = month_lens\n",
    "        \n",
    "        for j, month in enumerate(months):\n",
    "            index = 12*i + j\n",
    "            \n",
    "            day_tracker += month\n",
    "            monthly_data[:,:,index] = np.mean(daily_data[:,:,day_tracker-month:day_tracker], axis=2)\n",
    "            \n",
    "    return lat, lon, monthly_data\n",
    "\n",
    "lat, lon, monthly_olr = construct_seasons_from_days(olr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bac328a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make uniform grid data from the grib files, save as a single array\n",
    "\n",
    "def make4x4_grid_olr(lat, lon, data):\n",
    "    '''\n",
    "    Puts data from a given season of OLR data on a uniform 4 degree by 4 degree grid\n",
    "    \n",
    "    parameters: latitude and longitude of OLR values (1D arrays) and a 2D array of one month of OLR data\n",
    "    \n",
    "    returns 4x4 latitudes, longitudes, data\n",
    "    \n",
    "    '''\n",
    "    \n",
    "    # make an interpolating function for the original data\n",
    "    interp = RegularGridInterpolator((lat, lon), data)\n",
    "    \n",
    "    # then data are interpolated on a 4 degree grid using the median values of the 2 degree grids\n",
    "    latitude4 = np.flip(np.arange(-88.0, 90.0, 4.0)) # goes from 88 to -88\n",
    "    longitude4 = np.arange(2.0, 360.0, 4.0) # only goes up to 358\n",
    "    \n",
    "    # longitude is like x coordinate, latitude is like y coordinate\n",
    "    Lon4, Lat4 = np.meshgrid(longitude4, latitude4)\n",
    "    \n",
    "    data4 = interp((Lat4, Lon4))\n",
    "    \n",
    "    return Lat4, Lon4, data4\n",
    "\n",
    "def construct_data_array_olr(lat,lon,seasonal_data_array):\n",
    "    '''\n",
    "    Constructs an array of data with each index alonh axis=2 corresponding to a month of data\n",
    "    \n",
    "    input grbs_array is the output from open_anl_surf for a given variable\n",
    "    \n",
    "    '''\n",
    "    latitude4 = np.flip(np.arange(-88.0, 90.0, 4.0)) # goes from 88 to -88\n",
    "    longitude4 = np.arange(2.0, 360.0, 4.0) # only goes up to 358.0\n",
    "    lat_mask = (-30 <= latitude4) & (30 >= latitude4)\n",
    "    lon_mask = (100 <= longitude4) & (290 >= longitude4)\n",
    "    \n",
    "    Lon4, Lat4 = np.meshgrid(longitude4, latitude4)\n",
    "    \n",
    "    # select ENSO region\n",
    "    lat4_mask = (-30 <= Lat4) & (30 >= Lat4)\n",
    "    lon4_mask = (100 <= Lon4) & (290 >= Lon4)\n",
    "    ENSO_area_mask = lat4_mask & lon4_mask\n",
    "    ENSO_3D_mask = np.repeat(ENSO_area_mask[:, :, np.newaxis], (num_yrs*12), axis=2)\n",
    "    \n",
    "    processed_data = np.zeros(ENSO_3D_mask.shape)\n",
    "    \n",
    "    for i in range(seasonal_data_array.shape[2]):\n",
    "        olr = seasonal_data_array[:,:,i]\n",
    "        Lat, Lon, data = make4x4_grid_olr(lat,lon,olr)\n",
    "        processed_data[:,:,i] = data\n",
    "            \n",
    "    \n",
    "    return np.reshape(processed_data[ENSO_3D_mask], (len(latitude4[lat_mask]), len(longitude4[lon_mask]), (num_yrs*12)))\n",
    "\n",
    "olr = construct_data_array_olr(lat,lon,monthly_olr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ce93f578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_standardized_anomoly(data):\n",
    "    '''\n",
    "    Calculates standardized anomoly for given data (only parameter)\n",
    "    Data should already be in offset month bins (Dec-Jan, Jan-Feb, etc.) and normal 4x4 grid spacing\n",
    "    \n",
    "    standardized anomoly = (value - avg value for given time range) / standard deviation in given time range\n",
    "    \n",
    "    '''\n",
    "    mean = np.mean(data, axis=2)\n",
    "    stdev = np.std(data, axis=2)\n",
    "    \n",
    "    mean_array = np.repeat(mean[:, :, np.newaxis], data.shape[2], axis=2)\n",
    "    stdev_array = np.repeat(stdev[:, :, np.newaxis], data.shape[2], axis=2)\n",
    "    \n",
    "    standardized_anomoly = data\n",
    "    \n",
    "    standardized_anomoly -= mean_array\n",
    "    standardized_anomoly /= stdev_array\n",
    "    \n",
    "    return standardized_anomoly\n",
    "\n",
    "standardized_pressure = calculate_standardized_anomoly(pressure)\n",
    "standardized_temperature = calculate_standardized_anomoly(temperature)\n",
    "standardized_uwind = calculate_standardized_anomoly(uwind)\n",
    "standardized_vwind = calculate_standardized_anomoly(vwind)\n",
    "standardized_olr = calculate_standardized_anomoly(olr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73088de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the processed variable data, if desired\n",
    "# This will save the standardized anomolies of the variables, but perhaps we want the regular values (not standardized) for prediction\n",
    "\n",
    "np.save('standardized_pressure.npy',standardized_pressure)\n",
    "np.save('standardized_temperature.npy',standardized_temperature)\n",
    "np.save('standardized_uwind.npy',standardized_uwind)\n",
    "np.save('standardized_vwind.npy',standardized_vwind)\n",
    "np.save('standardized_olr.npy',standardized_olr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101e25f5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
